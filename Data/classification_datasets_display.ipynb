{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModularyNN Dataset Examples for Classification\n",
    "\n",
    "This notebook demonstrates the various dataset classes available in the ModularyNN framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import local modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "# Import dataset classes\n",
    "from Data.DatasetClasses import (\n",
    "    RandomData, \n",
    "    IrisData, \n",
    "    DigitData, \n",
    "    MNISTData, \n",
    "    CaltechData, \n",
    "    CifarData\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RandomData\n",
    "\n",
    "RandomData generates random inputs and one-hot encoded labels for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RandomData with 100 features and 5 categories\n",
    "random_data = RandomData(input_size=100, batch_size=32, categories=5)\n",
    "\n",
    "# Print dataset information\n",
    "random_data.print_dataset_info(\"Random Data\")\n",
    "\n",
    "# Show a sample\n",
    "print(\"\\nShowing a random sample:\")\n",
    "random_index = np.random.randint(0, random_data._input_tensor_train.shape[0])\n",
    "random_data.show_sample(random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IrisData\n",
    "\n",
    "The classic Iris dataset with 4 features and 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IrisData\n",
    "iris_data = IrisData(batch_size=16)\n",
    "\n",
    "# Print dataset information\n",
    "iris_data.print_dataset_info(\"Iris Data\")\n",
    "\n",
    "# Show a sample\n",
    "print(\"\\nShowing a random sample:\")\n",
    "random_index = np.random.randint(0, iris_data._input_tensor_train.shape[0])\n",
    "iris_data.show_sample(random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DigitData\n",
    "\n",
    "The scikit-learn digits dataset with 8x8 images of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DigitData\n",
    "digit_data = DigitData(batch_size=16)\n",
    "\n",
    "# Print dataset information\n",
    "digit_data.print_dataset_info(\"Digit Data\")\n",
    "\n",
    "# Show a sample\n",
    "print(\"\\nShowing a random sample:\")\n",
    "random_index = np.random.randint(0, digit_data._input_tensor_train.shape[0])\n",
    "digit_data.show_sample(random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MNISTData\n",
    "\n",
    "The MNIST dataset with 28x28 grayscale images of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MNISTData\n",
    "mnist_data = MNISTData(batch_size=64)\n",
    "\n",
    "# Print dataset information\n",
    "mnist_data.print_dataset_info(\"MNIST Data\")\n",
    "\n",
    "# Show a sample\n",
    "print(\"\\nShowing a random sample:\")\n",
    "random_index = np.random.randint(0, mnist_data._input_tensor_train.shape[0])\n",
    "mnist_data.show_sample(random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CaltechData\n",
    "\n",
    "The Caltech101 dataset with images of objects from 101 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CaltechData\n",
    "caltech_data = CaltechData(batch_size=32, image_size=(64, 64))\n",
    "\n",
    "# Print dataset information\n",
    "caltech_data.print_dataset_info(\"Caltech101\")\n",
    "\n",
    "# Show sample categories\n",
    "category_names = list(caltech_data.label_mapping.keys())\n",
    "print(f\"\\nSample categories (out of {len(category_names)}):\")\n",
    "for i in range(min(10, len(category_names))):\n",
    "    print(f\"  - {category_names[i]}\")\n",
    "\n",
    "# Show a sample\n",
    "print(\"\\nShowing a random sample:\")\n",
    "random_index = np.random.randint(0, caltech_data._input_tensor_train.shape[0])\n",
    "caltech_data.show_sample(random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CifarData\n",
    "\n",
    "The CIFAR-10 dataset with 32x32 RGB images in 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CifarData\n",
    "cifar_data = CifarData(batch_size=64)\n",
    "\n",
    "# Print dataset information\n",
    "cifar_data.print_dataset_info(\"Cifar Data\")\n",
    "\n",
    "# Show classes\n",
    "print(f\"\\nClass names: {cifar_data.classes}\")\n",
    "\n",
    "# Show a sample\n",
    "print(\"\\nShowing a random sample:\")\n",
    "random_index = np.random.randint(0, cifar_data._input_tensor_train.shape[0])\n",
    "cifar_data.show_sample(random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Size Comparison\n",
    "\n",
    "Let's compare the sizes of all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all datasets\n",
    "datasets = {\n",
    "    \"Random\": RandomData(input_size=100, batch_size=32, categories=5),\n",
    "    \"Iris\": IrisData(batch_size=16),\n",
    "    \"Digit\": DigitData(batch_size=16),\n",
    "    \"MNIST\": MNISTData(batch_size=64),\n",
    "    \"CIFAR-10\": CifarData(batch_size=64),\n",
    "    \"Caltech101\": CaltechData(batch_size=32, image_size=(64, 64))\n",
    "}\n",
    "\n",
    "# Extract information\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "sample_shapes = []\n",
    "class_counts = []\n",
    "names = []\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "    names.append(name)\n",
    "    train_sizes.append(dataset._input_tensor_train.shape[0])\n",
    "    test_sizes.append(dataset._input_tensor_test.shape[0])\n",
    "    sample_shapes.append(str(dataset._input_tensor_train.shape[1:]))\n",
    "    class_counts.append(dataset._label_tensor_train.shape[1])\n",
    "    \n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot dataset sizes\n",
    "plt.subplot(2, 1, 1)\n",
    "x = np.arange(len(names))\n",
    "width = 0.35\n",
    "plt.bar(x - width/2, train_sizes, width, label='Training')\n",
    "plt.bar(x + width/2, test_sizes, width, label='Test')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Number of Samples (log scale)')\n",
    "plt.title('Dataset Sizes')\n",
    "plt.xticks(x, names)\n",
    "plt.legend()\n",
    "\n",
    "# Plot number of classes\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(names, class_counts)\n",
    "plt.ylabel('Number of Classes')\n",
    "plt.title('Number of Classes per Dataset')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add sample shape as text\n",
    "for i, shape in enumerate(sample_shapes):\n",
    "    plt.text(i, class_counts[i] + 2, f\"Shape: {shape}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Dataset':<15} {'Train Samples':<15} {'Test Samples':<15} {'Sample Shape':<20} {'Classes':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for i, name in enumerate(names):\n",
    "    print(f\"{name:<15} {train_sizes[i]:<15} {test_sizes[i]:<15} {sample_shapes[i]:<20} {class_counts[i]:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Iteration Example\n",
    "\n",
    "Demonstrate how to iterate through batches for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset (MNIST) for demonstration\n",
    "mnist_data = MNISTData(batch_size=32)\n",
    "\n",
    "# Get a few batches\n",
    "print(\"Getting batches from MNIST dataset:\")\n",
    "for i in range(3):\n",
    "    inputs, labels = mnist_data.next()\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(f\"  Input shape: {inputs.shape}\")\n",
    "    print(f\"  Label shape: {labels.shape}\")\n",
    "    \n",
    "    # Count the distribution of digits in the batch\n",
    "    digit_counts = np.zeros(10, dtype=int)\n",
    "    for label in labels:\n",
    "        digit = np.argmax(label)\n",
    "        digit_counts[digit] += 1\n",
    "    \n",
    "    print(f\"  Digit distribution: {digit_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Dataset Sample Visualization\n",
    "\n",
    "Let's visualize samples from all datasets side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure for image datasets\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "random_index = np.random.randint(0, digit_data._input_tensor_train.shape[0])\n",
    "img = digit_data._input_tensor_train[random_index, 0]\n",
    "label = np.argmax(digit_data._label_tensor_train[random_index])\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"Digit Dataset - Class: {label}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "random_index = np.random.randint(0, mnist_data._input_tensor_train.shape[0])\n",
    "img = mnist_data._input_tensor_train[random_index, 0]\n",
    "label = np.argmax(mnist_data._label_tensor_train[random_index])\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"MNIST Dataset - Class: {label}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "random_index = np.random.randint(0, cifar_data._input_tensor_train.shape[0])\n",
    "img = cifar_data._input_tensor_train[random_index].transpose(1, 2, 0)\n",
    "label = np.argmax(cifar_data._label_tensor_train[random_index])\n",
    "plt.imshow(img)\n",
    "plt.title(f\"CIFAR-10 Dataset - Class: {cifar_data.classes[label]}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "try:\n",
    "    random_index = np.random.randint(0, caltech_data._input_tensor_train.shape[0])\n",
    "    img = caltech_data._input_tensor_train[random_index].transpose(1, 2, 0)\n",
    "    label = np.argmax(caltech_data._label_tensor_train[random_index])\n",
    "    category = next(cat for cat, idx in caltech_data.label_mapping.items() if idx == label)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Caltech101 Dataset - Class: {category}\")\n",
    "    plt.axis('off')\n",
    "except (FileNotFoundError, AttributeError) as e:\n",
    "    plt.text(0.5, 0.5, \"Caltech101 dataset not available\\nor not extracted\", \n",
    "             ha='center', va='center', fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Image Dataset Samples\", fontsize=16, y=1.05)\n",
    "plt.show()\n",
    "\n",
    "# Create figure for non-image datasets\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "random_index = np.random.randint(0, random_data._input_tensor_train.shape[0])\n",
    "features = random_data._input_tensor_train[random_index]\n",
    "label = np.argmax(random_data._label_tensor_train[random_index])\n",
    "plt.plot(features)\n",
    "plt.title(f\"Random Dataset - Class: {label}\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "random_index = np.random.randint(0, iris_data._input_tensor_train.shape[0])\n",
    "features = iris_data._input_tensor_train[random_index]\n",
    "label = np.argmax(iris_data._label_tensor_train[random_index])\n",
    "class_names = ['setosa', 'versicolor', 'virginica']\n",
    "feature_names = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "plt.bar(feature_names, features)\n",
    "plt.title(f\"Iris Dataset - Class: {class_names[label]}\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim([0, 1])  # Normalized features\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Non-Image Dataset Samples\", fontsize=16, y=1.05)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
